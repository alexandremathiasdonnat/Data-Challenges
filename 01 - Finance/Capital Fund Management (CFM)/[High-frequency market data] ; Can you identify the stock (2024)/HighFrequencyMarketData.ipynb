{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f84cad9e",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/7/74/Logo_%C3%89cole_normale_sup%C3%A9rieure_-_PSL_%28ENS-PSL%29.svg\"\n",
    "             alt=\"ENS-PSL\"\n",
    "             width=\"475\"\n",
    "             style=\"margin-right: 30px; display: inline-block; vertical-align: middle;\"/>\n",
    "    <img src=\"https://challengedata.ens.fr/logo/public/CFM_CoRGB_300dpi_Tight_box_Er2kNvB.png\"\n",
    "             alt=\"Crédit Agricole Assurances\"\n",
    "             width=\"260\"\n",
    "             style=\"display: inline-block; vertical-align: middle;\"/>\n",
    "</p>\n",
    "\n",
    "# Capital Fund Management - High Frequency Market Data Microstructure Classification\n",
    "**Deep Learning for Stock Identity Recognition from Order Book Sequences**\n",
    "\n",
    "## Data Challenge \n",
    "**Powered by ENS** \n",
    "\n",
    "<h3><span style=\"color:#800000;\"><strong>Authored by:</strong> <em>Alexandre Mathias DONNAT, Sr</em></span></h3>\n",
    "\n",
    "**Curently ranked 28/253** on *https://challengedata.ens.fr/challenges/146*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae07c52",
   "metadata": {},
   "source": [
    "This notebook presents a deep-learning framework for identifying anonymous equities from short sequences of order-book events.\n",
    "The objective is to classify each 100-event sequence into one of 24 equity classes (over 1000+ unique different and unknown 100-event sequences), using both numerical microstructure variables and categorical market-event descriptors.\n",
    "\n",
    "Each training sample consists of:\n",
    "\n",
    "- **1000+ unique, different and unknow 100 consecutive events** for a single stock,\n",
    "\n",
    "- **Microstructural features** describing bid/ask dynamics, trade activity, order flow direction, and venue information,\n",
    "\n",
    "- An **anonymous label** eqt_code_cat ∈ {0,…,23} representing a stock id\n",
    "\n",
    "The challenge is therefore to learn the microstructure signature of each equity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6737366b",
   "metadata": {},
   "source": [
    "## Understanding the modeling problem\n",
    "\n",
    "Each `obs_id` corresponds to:\n",
    "\n",
    "- a contiguous sequence of **100 market events**,\n",
    "- describing **one stock**,\n",
    "- but the identity of that stock is **anonymized**.\n",
    "\n",
    "Our task is:\n",
    "\n",
    "> **Given 100 high-frequency events, predict which of the 24 hidden stocks generated them.**\n",
    "\n",
    "Microstructure patterns differ across equities due to:\n",
    "\n",
    "- **volatility regimes**\n",
    "- **liquidity and spread behavior**\n",
    "- **order imbalances**\n",
    "- **typical trade sizes and venues**\n",
    "- **market activity cycles**\n",
    "\n",
    "These differences create **statistical fingerprints** that deep learning can extract.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf27509",
   "metadata": {},
   "source": [
    "## Description of the data\n",
    "\n",
    "#### 1) `x_train.csv` - Order-book event features\n",
    "\n",
    "Contains 104 850 events, forming 1 048 sequences of 100 events each;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5f67dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_id</th>\n",
       "      <th>venue</th>\n",
       "      <th>order_id</th>\n",
       "      <th>action</th>\n",
       "      <th>side</th>\n",
       "      <th>price</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>trade</th>\n",
       "      <th>flux</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   obs_id  venue  order_id action side  price  bid   ask  bid_size  ask_size  \\\n",
       "0       0      4         0      A    A   0.30  0.0  0.01       100         1   \n",
       "1       0      4         1      A    B  -0.17  0.0  0.01       100         1   \n",
       "2       0      4         2      D    A   0.28  0.0  0.01       100         1   \n",
       "3       0      4         3      A    A   0.30  0.0  0.01       100         1   \n",
       "4       0      4         4      D    A   0.37  0.0  0.01       100         1   \n",
       "\n",
       "   trade  flux  \n",
       "0  False   100  \n",
       "1  False   100  \n",
       "2  False  -100  \n",
       "3  False   100  \n",
       "4  False  -100  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"x_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0626a59",
   "metadata": {},
   "source": [
    "#### Variables include:\n",
    "\n",
    "**Numerical features:**\n",
    "- **prices**: `price`, `bid`, `ask`\n",
    "- **volumes**: `bid_size`, `ask_size`\n",
    "- **flow**: `flux` (signed order flow)\n",
    "\n",
    "**Categorical features:**\n",
    "- `venue` – trading venue identifier\n",
    "- `side` – order side (A/B, representing bid/ask or buy/sell)\n",
    "- `action` – order action type (A=Add, D=Delete, etc.)\n",
    "- `trade` – boolean flag indicating if event is a trade\n",
    "\n",
    "These are anonymized but carry meaningful **microstructural patterns** that distinguish equities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319323",
   "metadata": {},
   "source": [
    "#### 2) `y_train.csv` - Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f22129e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_id</th>\n",
       "      <th>eqt_code_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   obs_id  eqt_code_cat\n",
       "0       0            10\n",
       "1       1            15\n",
       "2       2             0\n",
       "3       3            13\n",
       "4       4             0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv(\"y_train.csv\")\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d34a466",
   "metadata": {},
   "source": [
    "For each sequence ID (`obs_id`), we have the true class:\n",
    "\n",
    "- **`eqt_code_cat`** — integer from 0 to 23 representing the anonymous stock identity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5f5d6a",
   "metadata": {},
   "source": [
    "#### 3)  `x_test.csv`- Sequences to classify\n",
    "\n",
    "Same format as x_train, without labels.\n",
    "\n",
    "Our final output simillary to y_train.csv, also contains : obs_id, eqt_code_cat but predicted from x_test.csv.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5730813e",
   "metadata": {},
   "source": [
    "## How the scoring works\n",
    "\n",
    "Evaluation uses accuracy:\n",
    "\n",
    "$$\\text{Accuracy} = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{1}\\{\\hat{y}_i = y_i\\}$$\n",
    "\n",
    "Therefore, all model selection must rely on internal validation.\n",
    "\n",
    "## The problem to solve\n",
    "\n",
    "We face a multiclass sequence classification task:\n",
    "\n",
    "- **24 classes**\n",
    "- **160,800 sequences** (from 16,080,000 rows ÷ 100 time steps)\n",
    "- Each sequence: **100 time steps** × (numerical + categorical features)\n",
    "\n",
    "Microstructure data are non-stationary, noisy, and order-dependent, which justifies the use of recurrent deep models.\n",
    "\n",
    "## Modeling pipeline\n",
    "\n",
    "Below is the full pipeline including preprocessing, sequence reconstruction, model architecture, mathematical foundations, and parameter choices.\n",
    "\n",
    "### I - Preprocessing\n",
    "\n",
    "#### I.1 Reconstructing sequences\n",
    "\n",
    "We reshape the long table (16,080,000 rows) into sequences:\n",
    "\n",
    "$$X \\in \\mathbb{R}^{N_{\\text{seq}} \\times 100 \\times d}$$\n",
    "\n",
    "with:\n",
    "- $N_{\\text{seq}} = 160{,}800$\n",
    "- $100$ events per sequence\n",
    "- $d =$ number of features\n",
    "\n",
    "This restores temporal order.\n",
    "\n",
    "#### I.2 Feature structuring\n",
    "\n",
    "**Numerical features**\n",
    "\n",
    "We keep them as real-valued vectors, optionally scaled for stability.\n",
    "\n",
    "**Categorical features**\n",
    "\n",
    "We encode:\n",
    "- `venue`\n",
    "- `action` (action_type)\n",
    "- `side`\n",
    "- `trade` (trade_type)\n",
    "\n",
    "as embeddings, i.e., learnable vectors:\n",
    "\n",
    "$$\\text{Embed}(c) = W_c \\in \\mathbb{R}^k$$\n",
    "\n",
    "**Why embeddings?**\n",
    "- reduce sparsity\n",
    "- capture similarity relations\n",
    "- improve convergence\n",
    "- standard in sequence models (analogy with NLP)\n",
    "\n",
    "Typical dimension: $k = 8$ or $16$.\n",
    "\n",
    "#### I.3 Train-validation split\n",
    "\n",
    "We use an 80/20 split at the sequence level:\n",
    "- ensures independence\n",
    "- avoids leakage across time steps\n",
    "\n",
    "### II - Model architecture\n",
    "\n",
    "The architecture follows a **Bi-GRU sequence encoder** with heavy regularization.\n",
    "\n",
    "#### II.1 Embedding layers\n",
    "\n",
    "Each categorical channel becomes a dense representation:\n",
    "\n",
    "$$e_t = [e_t^{(\\text{venue})}, e_t^{(\\text{action})}, e_t^{(\\text{side})}, e_t^{(\\text{trade})}]$$\n",
    "\n",
    "These embeddings are concatenated with numerical features.\n",
    "\n",
    "#### II.2 Bidirectional GRU encoder\n",
    "\n",
    "A Gated Recurrent Unit (GRU) at each time step computes:\n",
    "\n",
    "$$h_t = \\text{GRU}(x_t, h_{t-1})$$\n",
    "\n",
    "In bidirectional mode:\n",
    "\n",
    "$$h_t^{\\text{bi}} = [h_t^{\\rightarrow}, h_t^{\\leftarrow}]$$\n",
    "\n",
    "**Why GRU?**\n",
    "- fewer parameters than LSTM\n",
    "- good for noisy HF data\n",
    "- stable hidden dynamics\n",
    "- works very well with ~100 time steps\n",
    "\n",
    "**Parameter choice:**\n",
    "- hidden dimension = 128\n",
    "- recurrent_dropout = 0.25\n",
    "- Bi-directional for richer temporal context\n",
    "\n",
    "#### II.3 Mathematical rationale for the GRU\n",
    "\n",
    "GRU applies gates:\n",
    "\n",
    "$$\\begin{align}\n",
    "z_t &= \\sigma(W_z x_t + U_z h_{t-1}) \\\\\n",
    "r_t &= \\sigma(W_r x_t + U_r h_{t-1}) \\\\\n",
    "\\tilde{h}_t &= \\tanh(W_h x_t + U_h (r_t \\odot h_{t-1})) \\\\\n",
    "h_t &= (1 - z_t) \\odot h_{t-1} + z_t \\odot \\tilde{h}_t\n",
    "\\end{align}$$\n",
    "\n",
    "These gates allow the model to:\n",
    "- retain long-range dependencies,\n",
    "- suppress noise,\n",
    "- adapt to regime changes in microstructure events.\n",
    "\n",
    "#### II.4 Regularisation strategy\n",
    "\n",
    "We employ:\n",
    "- **Dropout** (0.3–0.5)\n",
    "- **Recurrent dropout**\n",
    "- **Layer Normalization**\n",
    "- **L2 weight penalties**\n",
    "\n",
    "**Purpose:**\n",
    "- avoid overfitting on only ~160k sequences\n",
    "- enhance generalization\n",
    "- stabilize training\n",
    "\n",
    "Mathematically, L2 adds:\n",
    "\n",
    "$$L_{\\text{total}} = L_{\\text{CE}} + \\lambda \\|W\\|_2^2$$\n",
    "\n",
    "#### II.5 Softmax classifier + Label Smoothing\n",
    "\n",
    "The final dense layer outputs:\n",
    "\n",
    "$$\\hat{p}(y = k \\mid x) = \\text{softmax}(Wh + b)_k$$\n",
    "\n",
    "We apply label smoothing, modifying the target distribution:\n",
    "\n",
    "$$y_k^{\\text{LS}} = (1 - \\epsilon) \\mathbb{1}_{k=y} + \\frac{\\epsilon}{24}$$\n",
    "\n",
    "with $\\epsilon = 0.1$.\n",
    "\n",
    "This reduces over-confidence and improves generalization.\n",
    "\n",
    "### III - Training strategy\n",
    "\n",
    "#### III.1 Early stopping\n",
    "\n",
    "Stops when validation accuracy stops improving.\n",
    "\n",
    "**Reasoning:**\n",
    "- Stop if $\\Delta \\text{val\\_acc} < 0$ for 5 epochs\n",
    "\n",
    "#### III.2 Learning-rate scheduling\n",
    "\n",
    "We use:\n",
    "- `ReduceLROnPlateau`\n",
    "\n",
    "which updates:\n",
    "\n",
    "$$\\eta \\leftarrow \\eta / 3$$\n",
    "\n",
    "if validation does not improve.\n",
    "\n",
    "#### III.3 Model Checkpoint\n",
    "\n",
    "We save the best performing epoch, not the last one.\n",
    "\n",
    "This prevents late-epoch degradation due to overfitting.\n",
    "\n",
    "### IV — Re-training and Prediction\n",
    "\n",
    "After training, we:\n",
    "1. Reload the best GRU model (`best_model_cfm_gru.h5`)\n",
    "2. Apply identical preprocessing to `x_test`\n",
    "3. Predict class probabilities\n",
    "4. Take argmax across the 24 classes\n",
    "5. Produce `y_prediction.csv` accordingly\n",
    "\n",
    "## Idea behind sequence classification\n",
    "\n",
    "The model attempts to learn a mapping:\n",
    "\n",
    "$$f : \\mathbb{R}^{100 \\times d} \\longrightarrow \\{0, \\ldots, 23\\}$$\n",
    "\n",
    "This is equivalent to learning the probability distribution:\n",
    "\n",
    "$$p(y \\mid x_{1:100})$$\n",
    "\n",
    "Microstructure features embed subtle statistical signals:\n",
    "- spread regimes\n",
    "- volatility bursts\n",
    "- trade aggressor patterns\n",
    "- venue frequency distributions\n",
    "- bid/ask oscillation symmetry\n",
    "\n",
    "The Bi-GRU captures these patterns in its hidden state trajectory.\n",
    "\n",
    "## Possible further improvements\n",
    "\n",
    "#### 1. Larger or deeper sequence models\n",
    "Transformers (Performer, TFT, Informer)\n",
    "\n",
    "#### 2. Ensembles\n",
    "GRU + LSTM + CNN + transformer hybrid\n",
    "\n",
    "#### 3. Advanced feature engineering\n",
    "Event clustering, microstructure volatility metrics, OFI measures\n",
    "\n",
    "#### 4. Data augmentation\n",
    "Randomized rescaling, local shuffling, spread perturbation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4cd67f",
   "metadata": {},
   "source": [
    "# 0. Modules & configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651e7317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "\n",
    "SEQ_LEN   = 100   # sequence length\n",
    "N_CLASSES = 24    # eqt_code_cat ∈ {0,...,23}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621b2197",
   "metadata": {},
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c9f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (16080000, 12)\n",
      "X_test  : (8160000, 12)\n",
      "y_train : (160800, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_id</th>\n",
       "      <th>venue</th>\n",
       "      <th>order_id</th>\n",
       "      <th>action</th>\n",
       "      <th>side</th>\n",
       "      <th>price</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>trade</th>\n",
       "      <th>flux</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   obs_id  venue  order_id action side  price  bid   ask  bid_size  ask_size  \\\n",
       "0       0      4         0      A    A   0.30  0.0  0.01       100         1   \n",
       "1       0      4         1      A    B  -0.17  0.0  0.01       100         1   \n",
       "2       0      4         2      D    A   0.28  0.0  0.01       100         1   \n",
       "3       0      4         3      A    A   0.30  0.0  0.01       100         1   \n",
       "4       0      4         4      D    A   0.37  0.0  0.01       100         1   \n",
       "\n",
       "   trade  flux  \n",
       "0  False   100  \n",
       "1  False   100  \n",
       "2  False  -100  \n",
       "3  False   100  \n",
       "4  False  -100  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv(\"x_train.csv\")\n",
    "X_test  = pd.read_csv(\"x_test.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\")  # obs_id + eqt_code_cat\n",
    "\n",
    "print(\"X_train :\", X_train.shape)\n",
    "print(\"X_test  :\", X_test.shape)\n",
    "print(\"y_train :\", y_train.shape)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5bc5d6",
   "metadata": {},
   "source": [
    "# 2. Features preparation\n",
    "## 2.1 Sequential Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3722b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, ['price', 'bid', 'ask', 'log_bid_size', 'log_ask_size', 'log_abs_flux'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for df in (X_train, X_test):\n",
    "    df[\"log_bid_size\"] = np.log1p(df[\"bid_size\"].clip(lower=0))\n",
    "    df[\"log_ask_size\"] = np.log1p(df[\"ask_size\"].clip(lower=0))\n",
    "    df[\"log_abs_flux\"] = np.log1p(df[\"flux\"].abs())\n",
    "\n",
    "num_cols_seq = [\"price\", \"bid\", \"ask\", \"log_bid_size\", \"log_ask_size\", \"log_abs_flux\"]\n",
    "len(num_cols_seq), num_cols_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31396c91",
   "metadata": {},
   "source": [
    "## 2.2 Categorial variables encoding (embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6497c0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3, 2, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat for common mapping train+test\n",
    "all_venue  = pd.concat([X_train[\"venue\"],  X_test[\"venue\"]], axis=0)\n",
    "all_action = pd.concat([X_train[\"action\"], X_test[\"action\"]], axis=0)\n",
    "all_side   = pd.concat([X_train[\"side\"],   X_test[\"side\"]], axis=0)\n",
    "all_trade  = pd.concat([X_train[\"trade\"],  X_test[\"trade\"]], axis=0)\n",
    "\n",
    "venue2idx  = {v: i for i, v in enumerate(sorted(all_venue.unique()))}\n",
    "action2idx = {v: i for i, v in enumerate(sorted(all_action.unique()))}\n",
    "side2idx   = {v: i for i, v in enumerate(sorted(all_side.unique()))}\n",
    "trade2idx  = {v: i for i, v in enumerate(sorted(all_trade.unique()))}\n",
    "\n",
    "for df in (X_train, X_test):\n",
    "    df[\"venue_idx\"]  = df[\"venue\"].map(venue2idx).astype(\"int32\")\n",
    "    df[\"action_idx\"] = df[\"action\"].map(action2idx).astype(\"int32\")\n",
    "    df[\"side_idx\"]   = df[\"side\"].map(side2idx).astype(\"int32\")\n",
    "    df[\"trade_idx\"]  = df[\"trade\"].map(trade2idx).astype(\"int32\")\n",
    "\n",
    "VENUE_VOCAB  = len(venue2idx)\n",
    "ACTION_VOCAB = len(action2idx)\n",
    "SIDE_VOCAB   = len(side2idx)\n",
    "TRADE_VOCAB  = len(trade2idx)\n",
    "\n",
    "VENUE_VOCAB, ACTION_VOCAB, SIDE_VOCAB, TRADE_VOCAB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a2fb8a",
   "metadata": {},
   "source": [
    "# 3. Sequential Tensors Building\n",
    "## 3.1 Utilitary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3030888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequences(df, seq_len=SEQ_LEN):\n",
    "    \"\"\"\n",
    "    Build sequential tensors from a DataFrame X_train or X_test.\n",
    "    - Sort by (obs_id, order_id)\n",
    "    - Reshape in (n_obs, seq_len, features)\n",
    "    Return : num_seq, venue_seq, action_seq, side_seq, trade_seq, obs_ids_sorted\n",
    "    \"\"\"\n",
    "    df_sorted = df.sort_values([\"obs_id\", \"order_id\"]).reset_index(drop=True)\n",
    "    \n",
    "    obs_ids = df_sorted[\"obs_id\"].to_numpy()\n",
    "    # obs_ids is repeated seq_len times per sequence, we retrieve the unique in order\n",
    "    obs_ids_unique, idx_first = np.unique(obs_ids, return_index=True)\n",
    "    obs_ids_sorted = obs_ids_unique  # already sorted by construction\n",
    "    \n",
    "    n_obs = len(obs_ids_sorted)\n",
    "    assert len(df_sorted) == n_obs * seq_len, \\\n",
    "        f\"len(df_sorted)={len(df_sorted)} != n_obs*seq_len={n_obs}*{seq_len}\"\n",
    "    \n",
    "    # Select columns\n",
    "    num_array   = df_sorted[num_cols_seq].to_numpy().astype(\"float32\")\n",
    "    venue_array = df_sorted[\"venue_idx\"].to_numpy().astype(\"int32\")\n",
    "    action_array= df_sorted[\"action_idx\"].to_numpy().astype(\"int32\")\n",
    "    side_array  = df_sorted[\"side_idx\"].to_numpy().astype(\"int32\")\n",
    "    trade_array = df_sorted[\"trade_idx\"].to_numpy().astype(\"int32\")\n",
    "    \n",
    "    num_seq    = num_array.reshape(n_obs, seq_len, -1)\n",
    "    venue_seq  = venue_array.reshape(n_obs, seq_len)\n",
    "    action_seq = action_array.reshape(n_obs, seq_len)\n",
    "    side_seq   = side_array.reshape(n_obs, seq_len)\n",
    "    trade_seq  = trade_array.reshape(n_obs, seq_len)\n",
    "    \n",
    "    return num_seq, venue_seq, action_seq, side_seq, trade_seq, obs_ids_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2623e222",
   "metadata": {},
   "source": [
    "## 3.2 Sequential train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483f74ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160800, 100, 6), (160800, 100), 160800)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num_seq, train_venue_seq, train_action_seq, train_side_seq, train_trade_seq, obs_ids_train_sorted = build_sequences(X_train)\n",
    "\n",
    "train_num_seq.shape, train_venue_seq.shape, len(obs_ids_train_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bcaf85",
   "metadata": {},
   "source": [
    "## 3.3 Label alignement (fixed memory)\n",
    "\n",
    "Here we avoid \"`.set_index().loc[...]`\" that could return MemoryError.\n",
    "We simply do :\n",
    "\n",
    "- Sort y_train by obs_id,\n",
    "- We verify sorted list of obs_id de y_train = obs_ids_train_sorted,\n",
    "- We extract eqt_code_cat in the correct order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda14d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160800,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We first ensure that there is exactly one line per obs_id\n",
    "counts = y_train[\"obs_id\"].value_counts()\n",
    "assert counts.max() == 1, \"More than one line per obs_id in y_train?\"\n",
    "\n",
    "y_train_sorted = y_train.sort_values(\"obs_id\").reset_index(drop=True)\n",
    "\n",
    "# Check alignment\n",
    "obs_y = y_train_sorted[\"obs_id\"].to_numpy()\n",
    "assert np.array_equal(obs_y, obs_ids_train_sorted), \"Mismatch obs_id between X_train and y_train after sorting.\"\n",
    "\n",
    "y_seq = y_train_sorted[\"eqt_code_cat\"].to_numpy().astype(\"int32\")\n",
    "y_seq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6d56f2",
   "metadata": {},
   "source": [
    "## 3.4 Split train / validation (by sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41e876c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128640, 100, 6), (32160, 100, 6))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_obs_train = train_num_seq.shape[0]\n",
    "idx_all = np.arange(n_obs_train, dtype=\"int32\")\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    idx_all,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_seq\n",
    ")\n",
    "\n",
    "train_num_seq_ = train_num_seq[train_idx]\n",
    "val_num_seq_   = train_num_seq[val_idx]\n",
    "\n",
    "train_venue_seq_  = train_venue_seq[train_idx]\n",
    "val_venue_seq_    = train_venue_seq[val_idx]\n",
    "\n",
    "train_action_seq_ = train_action_seq[train_idx]\n",
    "val_action_seq_   = train_action_seq[val_idx]\n",
    "\n",
    "train_side_seq_   = train_side_seq[train_idx]\n",
    "val_side_seq_     = train_side_seq[val_idx]\n",
    "\n",
    "train_trade_seq_  = train_trade_seq[train_idx]\n",
    "val_trade_seq_    = train_trade_seq[val_idx]\n",
    "\n",
    "y_train_seq = y_seq[train_idx]\n",
    "y_val_seq   = y_seq[val_idx]\n",
    "\n",
    "train_num_seq_.shape, val_num_seq_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e6f297",
   "metadata": {},
   "source": [
    "## 3.5. Sequential test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08054369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((81600, 100, 6), 81600)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_num_seq, test_venue_seq, test_action_seq, test_side_seq, test_trade_seq, obs_ids_test_sorted = build_sequences(X_test)\n",
    "\n",
    "test_num_seq.shape, len(obs_ids_test_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0005329f",
   "metadata": {},
   "source": [
    "## 3.6 Memory cooling dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb8bcd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X_train, X_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6342aef7",
   "metadata": {},
   "source": [
    "# 4.  GRU bidirectionnal regularized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51812159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cfm_gru_bidir_regularized\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"cfm_gru_bidir_regularized\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ venue_seq           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_seq          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ side_seq            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ trade_seq           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ num_seq             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │ venue_seq[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> │ action_seq[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ side_seq[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ trade_seq[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ num_seq[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru_forward (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,432</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru_backward (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,432</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bi_concat           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gru_forward[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ gru_backward[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ bi_concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_hidden        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_hidden      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_hidden[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ logits (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,560</span> │ dropout_hidden[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ venue_seq           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ action_seq          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ side_seq            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ trade_seq           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ num_seq             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m6\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │         \u001b[38;5;34m48\u001b[0m │ venue_seq[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │         \u001b[38;5;34m24\u001b[0m │ action_seq[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m4\u001b[0m)    │          \u001b[38;5;34m8\u001b[0m │ side_seq[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m4\u001b[0m)    │          \u001b[38;5;34m8\u001b[0m │ trade_seq[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ num_seq[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m30\u001b[0m)   │         \u001b[38;5;34m60\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru_forward (\u001b[38;5;33mGRU\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m18,432\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru_backward (\u001b[38;5;33mGRU\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m18,432\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bi_concat           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ gru_forward[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ gru_backward[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ bi_concat[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_hidden        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_hidden      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_hidden[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ logits (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        │      \u001b[38;5;34m1,560\u001b[0m │ dropout_hidden[\u001b[38;5;34m0\u001b[0m… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,340</span> (184.92 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m47,340\u001b[0m (184.92 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,084</span> (183.92 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m47,084\u001b[0m (183.92 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_NUM = train_num_seq_.shape[-1]\n",
    "\n",
    "EMB_DIM_VENUE  = 8\n",
    "EMB_DIM_ACTION = 8\n",
    "EMB_DIM_SIDE   = 4\n",
    "EMB_DIM_TRADE  = 4\n",
    "\n",
    "GRU_UNITS      = 64\n",
    "DROPOUT_SEQ    = 0.20\n",
    "REC_DROPOUT    = 0.10\n",
    "DROPOUT_DENSE  = 0.40\n",
    "L2_REG         = 1e-4\n",
    "\n",
    "# Inputs\n",
    "num_input    = keras.Input(shape=(SEQ_LEN, N_NUM),      name=\"num_seq\")\n",
    "venue_input  = keras.Input(shape=(SEQ_LEN,), dtype=\"int32\", name=\"venue_seq\")\n",
    "action_input = keras.Input(shape=(SEQ_LEN,), dtype=\"int32\", name=\"action_seq\")\n",
    "side_input   = keras.Input(shape=(SEQ_LEN,), dtype=\"int32\", name=\"side_seq\")\n",
    "trade_input  = keras.Input(shape=(SEQ_LEN,), dtype=\"int32\", name=\"trade_seq\")\n",
    "\n",
    "# Embeddings\n",
    "venue_emb  = layers.Embedding(VENUE_VOCAB,  EMB_DIM_VENUE,  mask_zero=False)(venue_input)\n",
    "action_emb = layers.Embedding(ACTION_VOCAB, EMB_DIM_ACTION, mask_zero=False)(action_input)\n",
    "side_emb   = layers.Embedding(SIDE_VOCAB,   EMB_DIM_SIDE,   mask_zero=False)(side_input)\n",
    "trade_emb  = layers.Embedding(TRADE_VOCAB,  EMB_DIM_TRADE,  mask_zero=False)(trade_input)\n",
    "\n",
    "# Concatenate\n",
    "x_seq = layers.Concatenate(axis=-1)([num_input, venue_emb, action_emb, side_emb, trade_emb])\n",
    "x_seq = layers.LayerNormalization()(x_seq)\n",
    "\n",
    "# GRU forward / backward\n",
    "gru_fwd = layers.GRU(\n",
    "    GRU_UNITS,\n",
    "    return_sequences=False,\n",
    "    dropout=DROPOUT_SEQ,\n",
    "    recurrent_dropout=REC_DROPOUT,\n",
    "    name=\"gru_forward\"\n",
    ")\n",
    "gru_bwd = layers.GRU(\n",
    "    GRU_UNITS,\n",
    "    return_sequences=False,\n",
    "    go_backwards=True,\n",
    "    dropout=DROPOUT_SEQ,\n",
    "    recurrent_dropout=REC_DROPOUT,\n",
    "    name=\"gru_backward\"\n",
    ")\n",
    "\n",
    "x_fwd = gru_fwd(x_seq)\n",
    "x_bwd = gru_bwd(x_seq)\n",
    "\n",
    "x = layers.Concatenate(name=\"bi_concat\")([x_fwd, x_bwd])  # 128 dim\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.Dense(\n",
    "    64,\n",
    "    activation=\"selu\",\n",
    "    kernel_regularizer=keras.regularizers.l2(L2_REG),\n",
    "    name=\"dense_hidden\"\n",
    ")(x)\n",
    "\n",
    "x = layers.Dropout(DROPOUT_DENSE, name=\"dropout_hidden\")(x)\n",
    "\n",
    "outputs = layers.Dense(N_CLASSES, activation=\"softmax\", name=\"logits\")(x)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs={\n",
    "        \"num_seq\":    num_input,\n",
    "        \"venue_seq\":  venue_input,\n",
    "        \"action_seq\": action_input,\n",
    "        \"side_seq\":   side_input,\n",
    "        \"trade_seq\":  trade_input,\n",
    "    },\n",
    "    outputs=outputs,\n",
    "    name=\"cfm_gru_bidir_regularized\"\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40409dda",
   "metadata": {},
   "source": [
    "# 5. Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de6615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=False\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=3e-3)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_fn,\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b83cfa",
   "metadata": {},
   "source": [
    "\n",
    "# 6. Training with early stopping + ReduceLROnPlateau\n",
    "Notes : 1h+ time to run cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bdbf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\n",
      "Epoch 1: val_accuracy improved from None to 0.28265, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 155s - 154ms/step - accuracy: 0.1699 - loss: 2.6204 - val_accuracy: 0.2826 - val_loss: 2.1475 - learning_rate: 0.0030\n",
      "Epoch 2/35\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.28265 to 0.37711, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 156s - 155ms/step - accuracy: 0.2887 - loss: 2.1261 - val_accuracy: 0.3771 - val_loss: 1.8240 - learning_rate: 0.0030\n",
      "Epoch 3/35\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.37711 to 0.41835, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 157s - 156ms/step - accuracy: 0.3493 - loss: 1.9252 - val_accuracy: 0.4183 - val_loss: 1.6872 - learning_rate: 0.0030\n",
      "Epoch 4/35\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.41835 to 0.46029, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 152s - 151ms/step - accuracy: 0.3893 - loss: 1.8010 - val_accuracy: 0.4603 - val_loss: 1.5505 - learning_rate: 0.0030\n",
      "Epoch 5/35\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.46029 to 0.49263, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 148s - 147ms/step - accuracy: 0.4168 - loss: 1.7187 - val_accuracy: 0.4926 - val_loss: 1.4629 - learning_rate: 0.0030\n",
      "Epoch 6/35\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.49263 to 0.52043, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 216s - 215ms/step - accuracy: 0.4389 - loss: 1.6528 - val_accuracy: 0.5204 - val_loss: 1.4008 - learning_rate: 0.0030\n",
      "Epoch 7/35\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.52043 to 0.52534, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 161s - 160ms/step - accuracy: 0.4576 - loss: 1.6035 - val_accuracy: 0.5253 - val_loss: 1.3754 - learning_rate: 0.0030\n",
      "Epoch 8/35\n",
      "\n",
      "Epoch 8: val_accuracy improved from 0.52534 to 0.54956, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 154s - 153ms/step - accuracy: 0.4691 - loss: 1.5676 - val_accuracy: 0.5496 - val_loss: 1.3104 - learning_rate: 0.0030\n",
      "Epoch 9/35\n",
      "\n",
      "Epoch 9: val_accuracy improved from 0.54956 to 0.55124, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 175s - 174ms/step - accuracy: 0.4808 - loss: 1.5342 - val_accuracy: 0.5512 - val_loss: 1.2984 - learning_rate: 0.0030\n",
      "Epoch 10/35\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.55124\n",
      "1005/1005 - 141s - 141ms/step - accuracy: 0.4922 - loss: 1.5076 - val_accuracy: 0.5506 - val_loss: 1.2943 - learning_rate: 0.0030\n",
      "Epoch 11/35\n",
      "\n",
      "Epoch 11: val_accuracy improved from 0.55124 to 0.56794, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 124s - 123ms/step - accuracy: 0.5004 - loss: 1.4814 - val_accuracy: 0.5679 - val_loss: 1.2543 - learning_rate: 0.0030\n",
      "Epoch 12/35\n",
      "\n",
      "Epoch 12: val_accuracy improved from 0.56794 to 0.56990, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 123s - 122ms/step - accuracy: 0.5064 - loss: 1.4636 - val_accuracy: 0.5699 - val_loss: 1.2471 - learning_rate: 0.0030\n",
      "Epoch 13/35\n",
      "\n",
      "Epoch 13: val_accuracy improved from 0.56990 to 0.58047, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 131s - 131ms/step - accuracy: 0.5135 - loss: 1.4445 - val_accuracy: 0.5805 - val_loss: 1.2091 - learning_rate: 0.0030\n",
      "Epoch 14/35\n",
      "\n",
      "Epoch 14: val_accuracy improved from 0.58047 to 0.58604, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 126s - 126ms/step - accuracy: 0.5191 - loss: 1.4263 - val_accuracy: 0.5860 - val_loss: 1.1876 - learning_rate: 0.0030\n",
      "Epoch 15/35\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 0.58604\n",
      "1005/1005 - 122s - 121ms/step - accuracy: 0.5230 - loss: 1.4154 - val_accuracy: 0.5729 - val_loss: 1.2287 - learning_rate: 0.0030\n",
      "Epoch 16/35\n",
      "\n",
      "Epoch 16: val_accuracy improved from 0.58604 to 0.59350, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 138s - 138ms/step - accuracy: 0.5282 - loss: 1.4002 - val_accuracy: 0.5935 - val_loss: 1.1726 - learning_rate: 0.0030\n",
      "Epoch 17/35\n",
      "\n",
      "Epoch 17: val_accuracy improved from 0.59350 to 0.59916, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 137s - 136ms/step - accuracy: 0.5333 - loss: 1.3907 - val_accuracy: 0.5992 - val_loss: 1.1736 - learning_rate: 0.0030\n",
      "Epoch 18/35\n",
      "\n",
      "Epoch 18: val_accuracy improved from 0.59916 to 0.60351, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 127s - 126ms/step - accuracy: 0.5379 - loss: 1.3762 - val_accuracy: 0.6035 - val_loss: 1.1516 - learning_rate: 0.0030\n",
      "Epoch 19/35\n",
      "\n",
      "Epoch 19: val_accuracy did not improve from 0.60351\n",
      "1005/1005 - 162s - 161ms/step - accuracy: 0.5427 - loss: 1.3639 - val_accuracy: 0.6006 - val_loss: 1.1665 - learning_rate: 0.0030\n",
      "Epoch 20/35\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.60351\n",
      "1005/1005 - 188s - 187ms/step - accuracy: 0.5474 - loss: 1.3550 - val_accuracy: 0.5960 - val_loss: 1.1720 - learning_rate: 0.0030\n",
      "Epoch 21/35\n",
      "\n",
      "Epoch 21: val_accuracy improved from 0.60351 to 0.60435, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 113s - 112ms/step - accuracy: 0.5486 - loss: 1.3490 - val_accuracy: 0.6044 - val_loss: 1.1437 - learning_rate: 0.0030\n",
      "Epoch 22/35\n",
      "\n",
      "Epoch 22: val_accuracy improved from 0.60435 to 0.62006, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 122s - 121ms/step - accuracy: 0.5520 - loss: 1.3407 - val_accuracy: 0.6201 - val_loss: 1.1103 - learning_rate: 0.0030\n",
      "Epoch 23/35\n",
      "\n",
      "Epoch 23: val_accuracy did not improve from 0.62006\n",
      "1005/1005 - 137s - 136ms/step - accuracy: 0.5547 - loss: 1.3341 - val_accuracy: 0.6101 - val_loss: 1.1346 - learning_rate: 0.0030\n",
      "Epoch 24/35\n",
      "\n",
      "Epoch 24: val_accuracy did not improve from 0.62006\n",
      "1005/1005 - 124s - 123ms/step - accuracy: 0.5578 - loss: 1.3273 - val_accuracy: 0.6122 - val_loss: 1.1247 - learning_rate: 0.0030\n",
      "Epoch 25/35\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 0.62006\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.001500000013038516.\n",
      "1005/1005 - 112s - 112ms/step - accuracy: 0.5459 - loss: 1.3624 - val_accuracy: 0.6101 - val_loss: 1.1417 - learning_rate: 0.0030\n",
      "Epoch 26/35\n",
      "\n",
      "Epoch 26: val_accuracy did not improve from 0.62006\n",
      "1005/1005 - 113s - 113ms/step - accuracy: 0.5448 - loss: 1.3700 - val_accuracy: 0.6154 - val_loss: 1.1223 - learning_rate: 0.0015\n",
      "Epoch 27/35\n",
      "\n",
      "Epoch 27: val_accuracy improved from 0.62006 to 0.62114, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 113s - 112ms/step - accuracy: 0.5560 - loss: 1.3300 - val_accuracy: 0.6211 - val_loss: 1.0915 - learning_rate: 0.0015\n",
      "Epoch 28/35\n",
      "\n",
      "Epoch 28: val_accuracy improved from 0.62114 to 0.62677, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 115s - 114ms/step - accuracy: 0.5635 - loss: 1.3095 - val_accuracy: 0.6268 - val_loss: 1.0880 - learning_rate: 0.0015\n",
      "Epoch 29/35\n",
      "\n",
      "Epoch 29: val_accuracy improved from 0.62677 to 0.63088, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 134s - 133ms/step - accuracy: 0.5684 - loss: 1.2924 - val_accuracy: 0.6309 - val_loss: 1.0733 - learning_rate: 0.0015\n",
      "Epoch 30/35\n",
      "\n",
      "Epoch 30: val_accuracy improved from 0.63088 to 0.63165, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 135s - 135ms/step - accuracy: 0.5731 - loss: 1.2784 - val_accuracy: 0.6317 - val_loss: 1.0661 - learning_rate: 0.0015\n",
      "Epoch 31/35\n",
      "\n",
      "Epoch 31: val_accuracy did not improve from 0.63165\n",
      "1005/1005 - 142s - 141ms/step - accuracy: 0.5772 - loss: 1.2667 - val_accuracy: 0.6295 - val_loss: 1.0715 - learning_rate: 0.0015\n",
      "Epoch 32/35\n",
      "\n",
      "Epoch 32: val_accuracy improved from 0.63165 to 0.63209, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 127s - 126ms/step - accuracy: 0.5758 - loss: 1.2633 - val_accuracy: 0.6321 - val_loss: 1.0608 - learning_rate: 0.0015\n",
      "Epoch 33/35\n",
      "\n",
      "Epoch 33: val_accuracy improved from 0.63209 to 0.63355, saving model to best_model_cfm_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 - 131s - 131ms/step - accuracy: 0.5815 - loss: 1.2524 - val_accuracy: 0.6336 - val_loss: 1.0571 - learning_rate: 0.0015\n",
      "Epoch 34/35\n",
      "\n",
      "Epoch 34: val_accuracy did not improve from 0.63355\n",
      "1005/1005 - 125s - 125ms/step - accuracy: 0.5829 - loss: 1.2467 - val_accuracy: 0.6336 - val_loss: 1.0596 - learning_rate: 0.0015\n",
      "Epoch 35/35\n",
      "\n",
      "Epoch 35: val_accuracy did not improve from 0.63355\n",
      "1005/1005 - 142s - 141ms/step - accuracy: 0.5725 - loss: 1.2783 - val_accuracy: 0.6310 - val_loss: 1.0635 - learning_rate: 0.0015\n",
      "Restoring model weights from the end of the best epoch: 33.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS     = 35\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    \"best_model_cfm_gru.h5\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    patience=6,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    {\n",
    "        \"num_seq\":    train_num_seq_,\n",
    "        \"venue_seq\":  train_venue_seq_,\n",
    "        \"action_seq\": train_action_seq_,\n",
    "        \"side_seq\":   train_side_seq_,\n",
    "        \"trade_seq\":  train_trade_seq_,\n",
    "    },\n",
    "    y_train_seq,\n",
    "    validation_data=(\n",
    "        {\n",
    "            \"num_seq\":    val_num_seq_,\n",
    "            \"venue_seq\":  val_venue_seq_,\n",
    "            \"action_seq\": val_action_seq_,\n",
    "            \"side_seq\":   val_side_seq_,\n",
    "            \"trade_seq\":  val_trade_seq_,\n",
    "        },\n",
    "        y_val_seq,\n",
    "    ),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[checkpoint, early_stop, reduce_lr],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae9cbea",
   "metadata": {},
   "source": [
    "# 7. Best Model recall and validation check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd47c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.6336 - loss: 1.0571\n",
      "Validation loss, accuracy : [1.0571269989013672, 0.6335510015487671]\n"
     ]
    }
   ],
   "source": [
    "best_model = keras.models.load_model(\"best_model_cfm_gru.h5\")\n",
    "\n",
    "val_metrics = best_model.evaluate(\n",
    "    {\n",
    "        \"num_seq\":    val_num_seq_,\n",
    "        \"venue_seq\":  val_venue_seq_,\n",
    "        \"action_seq\": val_action_seq_,\n",
    "        \"side_seq\":   val_side_seq_,\n",
    "        \"trade_seq\":  val_trade_seq_,\n",
    "    },\n",
    "    y_val_seq,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Validation loss, accuracy :\", val_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd72bfcc",
   "metadata": {},
   "source": [
    "# 7.2. Submission DataFrame & sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d5a2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 43ms/step\n",
      "   obs_id  eqt_code_cat\n",
      "0       0            11\n",
      "1       1             3\n",
      "2       2            19\n",
      "3       3             6\n",
      "4       4            22\n",
      "eqt_code_cat\n",
      "0     3268\n",
      "1     3252\n",
      "2     2856\n",
      "3     2642\n",
      "4     5045\n",
      "5     4490\n",
      "6     4246\n",
      "7     3415\n",
      "8     2643\n",
      "9     4309\n",
      "10    3385\n",
      "11    2038\n",
      "12    7137\n",
      "13    3957\n",
      "14    1954\n",
      "15    2440\n",
      "16    2003\n",
      "17    3913\n",
      "18    2309\n",
      "19    5508\n",
      "20    1833\n",
      "21    2244\n",
      "22    3570\n",
      "23    3143\n",
      "Name: count, dtype: int64\n",
      "NaN dans submission :\n",
      "obs_id          0\n",
      "eqt_code_cat    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions on test set\n",
    "y_pred_proba = best_model.predict(\n",
    "    {\n",
    "        \"num_seq\":    test_num_seq,\n",
    "        \"venue_seq\":  test_venue_seq,\n",
    "        \"action_seq\": test_action_seq,\n",
    "        \"side_seq\":   test_side_seq,\n",
    "        \"trade_seq\":  test_trade_seq,\n",
    "    },\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Get the class with highest probability\n",
    "y_pred_test = y_pred_proba.argmax(axis=1).astype(\"int32\")\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"obs_id\": obs_ids_test_sorted,\n",
    "    \"eqt_code_cat\": y_pred_test\n",
    "})\n",
    "\n",
    "print(submission.head())\n",
    "print(submission[\"eqt_code_cat\"].value_counts().sort_index())\n",
    "\n",
    "print(\"NaN in submission:\")\n",
    "print(submission.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07ced5",
   "metadata": {},
   "source": [
    "# 7.3. Export CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a72fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> y_prediction.csv created\n"
     ]
    }
   ],
   "source": [
    "submission.to_csv(\"y_prediction.csv\", index=False)\n",
    "print(\">> y_prediction.csv created\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telecom_env312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
